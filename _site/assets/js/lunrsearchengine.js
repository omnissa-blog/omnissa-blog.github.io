
var documents = [{
    "id": 0,
    "url": "http://localhost:4000/404.html",
    "title": "404",
    "body": "404 Page does not exist!Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "http://localhost:4000/about/",
    "title": "About",
    "body": "ias excepturi sint occaecati cupiditate non provident, similique sunt in culpa qui officia deserunt mollitia animi, id est laborum et dolorum fuga. Et harum quidem rerum facilis est et expedita distinctio. Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod maxime placeat facere possimus, omnis voluptas assumenda est, omnis dolor repellendus. Temporibus autem quibusdam et aut officiis debiti "
    }, {
    "id": 2,
    "url": "http://localhost:4000/about",
    "title": "Mediumish Template for Jekyll",
    "body": "This website is built with Jekyll and Mediumish template for Jekyll. It's for demonstration purposes, no real content can be found. Mediumish template for Jekyll is compatible with Github pages, in fact even this demo is created with Github Pages and hosted with Github.  Documentation: Please, read the docs here. Questions or bug reports?: Head over to our Github repository! Buy me a coffeeThank you for your support! Your donation helps me to maintain and improve Mediumish . Buy me a coffee Documentation"
    }, {
    "id": 3,
    "url": "http://localhost:4000/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 4,
    "url": "http://localhost:4000/",
    "title": "Home",
    "body": "      Featured:                                                                                                                                                                                                           Proactive Bug Hunting and Error Monitoring with Sentry                              :               We don’t live in a perfect world, and software is no exception to that. Testing can’t always catch everything or anticipate every potential failure with. . . :                                                                                                                                                                       Dan Parrella                                30 May 2025                                                                                                                                                                                                                                                                                                                        Enhancing OAuth 2. 0 Security with PKCE: A Deep Dive into External Partner Integration                              :               Introduction In the modern digital landscape, security is paramount, especially when dealing with third-party integrations that require authentication and authorization. OAuth 2. 0 is widely adopted. . . :                                                                                                                                                                       Samar Prakash                                24 May 2025                                                                                                                                                          All Stories:                                                                                                     Proactive Bug Hunting and Error Monitoring with Sentry              :       We don’t live in a perfect world, and software is no exception to that. Testing can’t always catch everything or anticipate every potential failure with third-party dependencies or services. Code. . . :                                                                               Dan Parrella                30 May 2025                                                                                                                                     First cut: Individual Contributor to Engineering Manager              :       This is a reflection or retrospection and an attempt to share the takeaways of my journey so far. I started officially as an Engineering Manager in the last 8 months. . . . :                                                                               Aditya Shrotri                25 May 2025                                                                                                                                     Enhancing OAuth 2. 0 Security with PKCE: A Deep Dive into External Partner Integration              :       Introduction In the modern digital landscape, security is paramount, especially when dealing with third-party integrations that require authentication and authorization. OAuth 2. 0 is widely adopted as a secure authorization framework,. . . :                                                                               Samar Prakash                24 May 2025                                                                                                                                     Powerful things you can do with the Markdown editor              :       There are lots of powerful things you can do with the Markdown editor. If you’ve gotten pretty comfortable with writing in Markdown, then you may enjoy some more advanced tips. . . :                                                                                               12 Jun 2018                                                                                                                                     Education must also train one for quick, resolute and effective thinking.               :       There are lots of powerful things you can do with the Markdown editor:                                                                               John                12 Jun 2018                                                                                                                                     About Bundler                         1 2 3 4 5                      :       gem install bundler installs the bundler gem through RubyGems. You only need to install it once - not every time you create a new Jekyll project. Here are some additional. . . :                                                                                               12 May 2018                                               &laquo; Prev       1        2      Next &raquo; "
    }, {
    "id": 5,
    "url": "http://localhost:4000/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 6,
    "url": "http://localhost:4000/page2/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 7,
    "url": "http://localhost:4000/proactive-bug-hunting-and-error-monitoring-with-sentry/",
    "title": "Proactive Bug Hunting and Error Monitoring with Sentry",
    "body": "2025/05/30 - We don’t live in a perfect world, and software is no exception to that. Testing can’t always catch everything or anticipate every potential failure with third-party dependencies or services. Code reviewers and the engineers who wrote the code are susceptible to fatigue and human error. It is simply a fact that bugs and other errors are going to happen at some point. Acknowledging this truth requires that we have feedback mechanisms in place to let us know when unexpected errors occur, so that we can quickly investigate and resolve issues before they impact our customers. It’s even better (and much less expensive) when issues are detected before they can even reach our customers. This article tells the story of how the VMware Workspace ONE Intelligence team came to use Sentry to help us maintain a high standard of reliability and quality for our services. Background: Omnissa Workspace ONE Intelligence is a SaaS-based data analytics platform comprised of 40+ container-based microservices and dozens of lambdas running on AWS. We have deployments in regions around the world and a highly distributed team. Our platform ingests a ton of data from a wide variety of sources — roughly 4 TB per day in our busiest deployment! All sorts of interesting problems can happen at this scale and we are regularly pushing the limits of AWS. As such it’s extremely important for us to have solid tools that help us be aware of and troubleshoot issues. Log Monitoring with SumoLogic: Logs from our services and other components are sent to SumoLogic, which allows us to search and analyze log data. Some of the logs that make their way into SumoLogic are log statements added to our code (or that third-party libraries have added to theirs) to highlight potential error conditions. These logs generally have a WARN or ERROR level depending on the potential severity of the application state. We can then run queries for such logs to find errors. Further, those same queries can be executed to run on a schedule and trigger alerts when a log count threshold is reached. This log-based approach was used by our team for what we will call “Log Review” and “Log Monitoring. ” Log Review: The purpose of Log Review was to find problems in staging before code is released to production. During each sprint an engineer was assigned to a Log Review rotation. This meant that the engineer needed to remember to run a handful of queries against logs in our staging environment at least once a day. Any issues found that required a fix or further investigation were created as bugs or tasks under a log review Epic in JIRA. Log Review was problematic for a few reasons. Within a single sprint it was somewhat manageable for the assigned engineer to maintain context over which issues were new or previously triaged, but that context was easily lost when the next engineer came along. Some “tribal knowledge” was required in order to stay on top of things — which is not easy with a large and distributed team that continues to grow and develop microservices. But perhaps the biggest problem was that it required a human remembering to go in to SumoLogic and manually run queries to hunt for issues while also staying on top of their other tasks. This meant that some issues were only detected whenever someone went to look for them, which could mean hours or days going by as more code is merged. Finding the needle in the hay stack representing the offending commit is much harder when the haystack keeps growing. Log Monitoring: Log monitoring was essentially an automated set of queries for WARN and ERROR logs that would trigger PagerDuty alerts when any results were found. The queries were run on an hourly basis. Filters were periodically added to these queries to avoid noise from known issues. The team had some success with this approach. Because of the integration with PagerDuty, issues were generally quickly examined and triaged by the engineer on call. Filters were added if needed and the queries could be updated by our DevOps team to avoid continued noise. This approach had some serious drawbacks, however. The biggest issue was that the queries spanned multiple services and components. When a PagerDuty incident was created, it was not scoped to a particular component or issue. This meant that new incidents would not be created when the queries ran again as long as there was already an incident already open for the failing query. If the engineer on call forgot to resolve the incident after triage, then it was possible to not be alerted on new errors! Further, because the alerts spanned services, engineers didn’t immediately know where the problem was. Identifying the troubled system component(s) required running the SumoLogic query linked to the PagerDuty Incident, and visually scanning all of the results. Alerts only told the engineer “hey something is broken somewhere…go find it!” Another issue was timeliness in detecting errors, purely based on the fact that the queries were run on an hourly basis. Oftentimes the offending logs were intermittent failures from some external service that were already resolved by the time we got the PagerDuty alert. Finally, there was a lack of historical context for issues found in logs, for many of the same reasons we had this problem in Log Review. No release or commit information is associated with logs and there is no way to see the history of a log other than searching for the specific log or finding a ticket in JIRA. Context for issues discovered during an on-call rotation was lost as we rolled over to the next engineer. All of this added up in terms of engineering time and therefore cost. Goals To Improve: Log monitoring was helpful, but over time it was clear that we could do better. It was time-consuming, stressful, and prone to human error. In order to be really successful with error monitoring we needed a solution that would:  Provide rapid feedback Provide more specific alerts Provide enough context to troubleshoot problems quickly Keep track of problems over timeError Monitoring With Sentry: Sentry at its core is an error aggregator for a wide variety of platforms and programming languages. When an application is integrated with the Sentry SDK, error events are sent to Sentry as they occur and grouped together based on traits like stack trace or message. The grouping of issues makes it much easier to digest problems and has the added benefit of tracking when an issue was first seen and last seen, how frequently it happens, and what environments it has been spotted in. Error events can be generated in a number of ways - unhandled exceptions, failed HTTP requests in a web framework like Spring, or even “manually” in the code itself. What interested me the most though was the logback integration, which is the logging framework we were already using in all of our applications. With this integration we could generate error events from ERROR or WARN log statements that already existed in our code. You might be wondering why that’s any better than what we had with SumoLogic. The answer is: context! Sentry captures a lot of valuable information with each event. Some of those bits of information may include:  HTTP request information — status code, URL, headers Detailed stack traces Thread information Breadcrumbs — log statements preceding the error Release number EnvironmentIt’s also possible to configure additional context and tags for events. We use the additional context to capture things like git commit, branch name, build number, and build job name. Tags, which are automatically searchable, are used to attach information like the AWS account or the team that owns a particular service. All of this makes it much easier for engineers to troubleshoot and diagnose issues in our systems. We can rapidly identify what service a problem occurred in and when exactly that problem started. Further, we have context around the issue that is extremely helpful when debugging. Setting Up Projects: Sentry recommends creating a project for each code repository. Each one of our services maps to its own repository, so this was an easy fit. Because we had so many services already, we wrote a Ruby script that used the sentry-api Gem to provision projects for all services. This also makes provisioning projects for services in the future easier. Part of provisioning a project is the generation of a DSN, which is a credential the Sentry SDK uses to send events for that project. A project can have multiple DSNs, but for now we only use one. This could be useful if you wanted to use a different DSN for each environment and control rate limiting, for example. How you want to handle the DSN is up to you. It’s only good for publishing events, so it’s not extremely sensitive information and it can always be revoked and replaced. To be on the safe side, though, we store project DSNs as a secure string in the AWS Systems Manager Parameter Store. This happens in our provisioning script. Configuring Sentry: The Sentry SDK needs to be initialized with a DSN. This can happen automatically depending on your chosen integration, or with a call in your application bootstrapping code, which is as simple as: 123456// Retrieves DSN from your environment// sentry. dsn system property or SENTRY_DSN environment variableSentry. init();// Or you can supply it directlySentry. init( your-dsn-here );Because our services run as containers on the AWS Elastic Container Service, we can use ECS Secrets Manager to automatically fetch the DSN from the parameter store and supply it to the container environment with the SENTRY_DSN environment variable. Our lambdas unfortunately need to fetch the DSN from the parameter store themselves when they boot up, but this was fairly trivial for us to do. Getting Started With Logback Integration: Our code was already using the popular logback framework via SLF4J. Sentry offers the sentry-logback module, which includes the SentryAppender class. This can then be added to your logback configuration like any other appender and you are up and running! Configuration can be done programmatically or within your logback. xml file. Our lambdas use the logback. xml file to add the appender: 12345678910111213141516171819202122232425262728&lt;?xml version= 1. 0 ?&gt;&lt;configuration&gt;  &lt;!-- See https://github. com/jlib-framework/jlib-awslambda-logback#configuration --&gt;  &lt;appender name= awslambda  class= org. jlib. cloud. aws. lambda. logback. AwsLambdaAppender &gt;    &lt;encoder&gt;      &lt;charset&gt;UTF-8&lt;/charset&gt;      &lt;pattern&gt;%d %-4relative [AWS request ID: %X{AWSRequestId:- }] [%level] %logger - %msg%n&lt;/pattern&gt;    &lt;/encoder&gt;  &lt;/appender&gt;  &lt;!-- Configure the Sentry appender. --&gt;  &lt;appender name= sentry  class= io. sentry. logback. SentryAppender &gt;    &lt;options&gt;      &lt;!--        SentryAppender tries to initialize the Sentry SDK here and logs a        WARN message unless the DSN is set to an empty string. We initialize the Sentry SDK        ourselves after fetching the DSN from the AWS SSM parameter store.       --&gt;      &lt;dsn&gt;${SENTRY_DSN:- }&lt;/dsn&gt;    &lt;/options&gt;    &lt;minimumEventLevel&gt;${SENTRY_LOG_LEVEL:-WARN}&lt;/minimumEventLevel&gt;  &lt;/appender&gt;  &lt;root level= ${LOG_LEVEL:-WARN} &gt;    &lt;appender-ref ref= awslambda /&gt;    &lt;appender-ref ref= sentry /&gt;  &lt;/root&gt;&lt;/configuration&gt;While our services take the programmatic approach within a Spring [InitializingBean](https://docs. spring. io/spring-framework/docs/current/javadoc-api/org/springframework/beans/factory/InitializingBean. html: 1234567final SentryAppender sentryAppender = new SentryAppender();sentryAppender. setContext(loggerContext);sentryAppender. setMinimumEventLevel(Level. WARN);sentryAppender. setName( sentryAppender );sentryAppender. start();final Logger logbackLogger = (ch. qos. logback. classic. Logger)LoggerFactory. getLogger( ROOT );logbackLogger. addAppender(sentryAppender);With this configuration, all of our services and lambdas send error events to Sentry whenever a log statement with level WARN or higher is reached. 1log. error( this is a test-appender ); Configuring Alerts: Now that errors are coming in we want to know about it. Sentry supports two types of alerts: Metric and Issue. Both types of alerts support triggering actions with one or more integrations. We have the Slack and PagerDuty integrations set up. Depending on the rules in the alert the team will see a message in a Slack channel and/or a PagerDuty alert will be sent to the engineer on call. The Slack channel and configuration for the PagerDuty alert are based on an “environment_type” tag we apply to events. This helps us to reduce noise and prioritize based on where Issues are occurring. If something is breaking in prod, we want to be able to clearly see that. We do this by using a different Slack channel for prod and staging.  Issue alerts are centered around a single, specific Issue (grouped errors). We have alerts configured to let us know when:  A new issue has been created An issue is occurring frequently A resolved issue is re-opened (seen again)Because we want to route alerts based on “environment_type”, we have to create the same alerts for each type.  Metric alerts work based on counts across all issues within a project. Sentry billing works based on an event quota, and the alert pictured above is designed to make sure we are not caught off guard when we start seeing a high volume of events from any service in any environment. If the quota is reached, then Sentry could start to reject events. Handling Alerts: All engineers on the team can see alert activity in one or more Slack channels. PagerDuty alerts are also sent to an on-call engineer. When an engineer looks at the issue they can assign it to themselves, create a JIRA ticket if one is not already linked, or add comments to let other engineers know what investigation they’ve done. Errors now have historical context! Evaluating Sentry Against Our Goals: Provide rapid feedback: Alerts go to Slack and/or PagerDuty when they are triggered. We no longer wait up to an hour to be notified of issues. Also, instead of a single engineer receiving alerts, every member of the team can see activity in the Sentry Slack channel. Provide more specific alerts: Issue alerts let us know about a specific error in a specific service. The alert itself has the specific error in it. This means the on-call engineer can quickly glance at their phone and have some idea of where the problem is and how to prioritize it. Provide enough context to troubleshoot problems quickly: Sentry issues can provide a lot of useful context. We can see (scrubbed) request information, build/commit, history and we can add context ourselves where we need it. The build and historical information alone are invaluable in locating code that may have broken something. Keep track of problems over time: Sentry has removed the guesswork of determining whether an error is new or is known and already tracked. We know who has looked at the error and can see any activity or linked JIRA tickets. This represents a huge time savings for our engineers and cuts down on the “tribal knowledge” problem we had before. Conclusions: Sentry has been a great addition to our toolbox for monitoring and troubleshooting. We still need and use other tools like SumoLogic and CloudWatch, but it has become an excellent starting point for investigating issues both before and after deployment to production. The main struggle we had was getting alerts configured for all of our projects. The API that the UI uses is not technically public so it made writing our script to create alerts a challenge. Scripting to manage Sentry configuration is needed, especially for larger organizations, because setting up every project manually is definitely not scalable or fun. "
    }, {
    "id": 8,
    "url": "http://localhost:4000/ic-to-mgr/",
    "title": "First cut: Individual Contributor to Engineering Manager",
    "body": "2025/05/25 - This is a reflection or retrospection and an attempt to share the takeaways of my journey so far. I started officially as an Engineering Manager in the last 8 months. Before that, I was acting as a Tech Lead, just got promoted to Staff Software Engineer. I have been in the information technology industry for the last 10+ years and one of the things that were pretty clear to me since the beginning was that my personality is more people-oriented and I like to talk to people, engage with them along with spending time on solving technological problems. Few people see moving to a management role as a promotion but I always looked at it as a new role starting from ground zero and thus I need to be mindful of what needs to change in my daily routine/responsibilities going forward. I knew right off the bat that if I don’t change anything then I’ll be shooting myself in the foot. As an individual contributor, I was exposed to only technical problems but on the flip side, I’d be exposed to Products, People, Processes, and Technical Problems (Yes, you read that right!). Trust and Culture: Trust is a very important element in order to succeed as a team and thus it was important for me to plug myself into team members’ daily tasks and understand their concerns. The recurring 1:1s is a very useful tool in order to address these problems. I try to keep all team communications open and transparent. Lead with Context: Another challenge being in this role is you need to be technical, understand the technology and more importantly need to understand how that technology is intertwined into a product and define usage pattern and user experience for the customers. This ability gives an extra strength to lead the team in the right direction and get us to the desired outcome. Stakeholder Management: When I stepped into this role, stakeholder management became a day 1 operation for me as in getting alignment across the teams, unblocking upstream/downstream services, UX/Product Management team’s ever-changing requirements, and aligning priorities and deadlines. This seems difficult to achieve but with a great team, strong processes, and a sense of ownership within the teams, it definitely made it easier. Delegation: Moving from IC to Manager, one thing was pretty clear to me that I can not do everything on my own and if I’m going the same IC route, then I won’t be fair to my role and also not setting the team for success. I viewed my role now as a guard rail on the bowling alley whose job is to make sure the ball does not go into the gutter and redirect it back onto the target. It’s ever important to take a step back and let the technical lead take the ownership and not try to be the smartest person in the room. The more you listen, the better it gives others an opportunity to grow. Be Aware and Stay ahead: As an engineering manager, you receive information from the top, down, left, right and at the same time, questions come too. Since the teams are distributed geographically, it’s important to be aware and document everything in order to keep all information up to date and everyone on the same page. This really helped me fill those communication edge gaps and unblocked the team from time to time. "
    }, {
    "id": 9,
    "url": "http://localhost:4000/enhancing-oauth-2-0-security-with-pkce/",
    "title": "Enhancing OAuth 2.0 Security with PKCE: A Deep Dive into External Partner Integration",
    "body": "2025/05/24 - Introduction: In the modern digital landscape, security is paramount, especially when dealing with third-party integrations that require authentication and authorization. OAuth 2. 0 is widely adopted as a secure authorization framework, but traditional flows, such as the implicit flow, have proven vulnerable to security risks like token interception. To mitigate these risks, the Proof Key for Code Exchange (PKCE) extension was introduced, enhancing OAuth security by ensuring that authorization requests and token exchanges originate from the same client. This article explores how Omnissa Intelligence integrates with multiple External Partner services using OAuth 2. 0 with PKCE, offering a secure authentication mechanism that prevents authorization code interception attacks. What is Omnissa Intelligence?: Omnissa Intelligence is a data-driven platform that provides actionable insights across end-user computing (EUC) environments. It enables organizations to enhance security, performance, and compliance through intelligent automation, real-time analytics, and seamless integration with various enterprise solutions. By leveraging AI-driven insights, Omnissa Intelligence helps IT and security teams make informed decisions to optimize user experience and reduce operational risks. For more details, visit Omnissa Intelligence. What is PKCE?: PKCE (Proof Key for Code Exchange) is an enhancement to the OAuth 2. 0 authorization framework, designed specifically for public clients such as mobile apps, browser-based applications, and other applications where client secrets cannot be securely stored. PKCE helps protect against authorization code interception attacks by introducing dynamically generated code challenge and code verifier parameters. At a high level, this is an overview of how the flow appears.  Key PKCE Parameters:  Code Verifier: A cryptographically random string used to correlate the authorization request with the token request.  Code Challenge: A transformation of the code verifier (e. g. , SHA-256 hashed and Base64 URL encoded) sent in the authorization request.  Code Challenge Method: Specifies the method used to derive the code challenge, typically S256. Why PKCE is Critical for External Partner Integrations: External Partner services mandate PKCE-based OAuth 2. 0 integration for third-party applications such as Omnissa Intelligence to mitigate security threats. Traditional OAuth flows rely on client secrets, but public applications cannot store them securely. This introduces risks such as authorization code theft, allowing attackers to exchange stolen codes for access tokens, gaining unauthorized access to user data. By enforcing OAuth PKCE, External Partner services ensure that only the original requesting client can exchange an authorization code for an access token. This security measure protects against session hijacking, token theft, and man-in-the-middle attacks. PKCE Flow Overview: The OAuth 2. 0 PKCE flow for Omnissa Intelligence integrating with an External Partner follows these steps: During the initial step (https://external-partner. com/oauth/authorize) of the OAuth procedure, the Omnissa Intelligence Authorization Server provides the code_challenge parameter to the External Partner Authorization Server. After the user manually authorizes the application, the External Partner Authorization Server responds with an Authorization Code, which must then be returned to the External Partner Authorization Server along with the code_verifier parameter by the Omnissa Intelligence Authorization Server, in exchange for an Access Token. If the code_verifier parameter does not match the code_challenge provided by Omnissa Intelligence Authorization Server in the initial authorization request, this may indicate an attempted code injection attack. In this case, the External Partner Authorization Server should abort the OAuth process and return an error. If the External Partner Authorization Server verifies that the code_challenge and code_verifier match, the token exchange request is processed successfully, and the External Partner Authorization Server issues an Access Token via the token endpoint (https://external-partner. com/oauth/token). Sample Requests:Omnissa Intelligence redirects the user to the External Partner Authorization Server for authentication, including the Code Challenge in the request. 12345678910Authorization Requesthttps://partner-auth. com/oauth/authorize  ?response_type=code  &amp;client_id=OMNISSA_INTEL_CLIENT_ID  &amp;redirect_uri=OMNISSA_INTEL_REDIRECT_URI  &amp;code_challenge=GENERATED_CODE_CHALLENGE  &amp;code_challenge_method=S256  &amp;state=RANDOM_STATE  &amp;scope=REQUESTED_SCOPESThe External Partner redirects the user back to the Omnissa Intelligence Authorization Server redirection endpoint with Authorization Code &amp; State Parameter (to prevent CSRF attacks) 12345Redirect URLhttps://omnissa-intelligence. com/oauth/callback?code=AUTHORIZATION_CODE&amp;state=RANDOM_STATEThe Omnissa Intelligence Authorization Server sends a POST request to the External Partner Authorization Server, including Authorization Code, Code Verifier (original random string), Client ID &amp; Redirect URI 123456789Token Exchange(POST Request)POST https://partner-auth. com/oauth/tokenContent-Type: application/x-www-form-urlencodedgrant_type=authorization_code&amp;client_id=OMNISSA_INTEL_CLIENT_ID&amp;redirect_uri=OMNISSA_INTEL_REDIRECT_URI&amp;code=AUTHORIZATION_CODE&amp;code_verifier=ORIGINAL_CODE_VERIFIERThe External Partner Authorization Server validates: Authorization Code (to ensure it’s valid), Code Verifier (must match the previously hashed Code Challenge). If verification succeeds, the External Partner Authorization Server issues an Access Token &amp; Refresh Token. 12345678Token Response{ access_token :  ACCESS_TOKEN , token_type :  Bearer , refresh_token :  REFRESH_TOKEN , expires_in : 3600}Conclusion: By implementing OAuth 2. 0 with PKCE, Omnissa Intelligence ensures a secure, scalable, and compliant authentication flow when integrating with External Partner services. PKCE eliminates the need for client secrets, although in some cases, it is required with the Authorization Code. This helps reduce risks such as authorization code interception and token theft. This standardized OAuth 2. 0 PKCE flow provides a secure foundation for all future integrations, ensuring consistent authentication security across applications. Adopting PKCE enhances protection against evolving threats, making third-party integrations robust, reliable, and future-proof. For more details, visit Omnissa Intelligence. "
    }, {
    "id": 10,
    "url": "http://localhost:4000/powerful-things-markdown-editor/",
    "title": "Powerful things you can do with the Markdown editor",
    "body": "2018/06/12 - There are lots of powerful things you can do with the Markdown editor. If you’ve gotten pretty comfortable with writing in Markdown, then you may enjoy some more advanced tips about the types of things you can do with Markdown! As with the last post about the editor, you’ll want to be actually editing this post as you read it so that you can see all the Markdown code we’re using. Special formatting: As well as bold and italics, you can also use some other special formatting in Markdown when the need arises, for example:  strike through ==highlight== *escaped characters*Writing code blocks: There are two types of code elements which can be inserted in Markdown, the first is inline, and the other is block. Inline code is formatted by wrapping any word or words in back-ticks, like this. Larger snippets of code can be displayed across multiple lines using triple back ticks: 123. my-link {  text-decoration: underline;}HTML: 12345&lt;li class= ml-1 mr-1 &gt;  &lt;a target= _blank  href= # &gt;  &lt;i class= fab fa-twitter &gt;&lt;/i&gt;  &lt;/a&gt;&lt;/li&gt;CSS: 12345678. highlight . c {  color: #999988;  font-style: italic; }. highlight . err {  color: #a61717;  background-color: #e3d2d2; }JS: 123456789// alertbar later$(document). scroll(function () {  var y = $(this). scrollTop();  if (y &gt; 280) {    $('. alertbar'). fadeIn();  } else {    $('. alertbar'). fadeOut();  }});Python: 1print( Hello World )Ruby: 123require 'redcarpet'markdown = Redcarpet. new( Hello World! )puts markdown. to_htmlC: 1printf( Hello World ); Reference lists: The quick brown jumped over the lazy. Another way to insert links in markdown is using reference lists. You might want to use this style of linking to cite reference material in a Wikipedia-style. All of the links are listed at the end of the document, so you can maintain full separation between content and its source or reference. Full HTML: Perhaps the best part of Markdown is that you’re never limited to just Markdown. You can write HTML directly in the Markdown editor and it will just work as HTML usually does. No limits! Here’s a standard YouTube embed code as an example: "
    }, {
    "id": 11,
    "url": "http://localhost:4000/education/",
    "title": "Education must also train one for quick, resolute and effective thinking.",
    "body": "2018/06/12 - There are lots of powerful things you can do with the Markdown editor If you’ve gotten pretty comfortable with writing in Markdown, then you may enjoy some more advanced tips about the types of things you can do with Markdown! As with the last post about the editor, you’ll want to be actually editing this post as you read it so that you can see all the Markdown code we’re using. Special formatting: As well as bold and italics, you can also use some other special formatting in Markdown when the need arises, for example:  strike through ==highlight== *escaped characters*Writing code blocks: There are two types of code elements which can be inserted in Markdown, the first is inline, and the other is block. Inline code is formatted by wrapping any word or words in back-ticks, like this. Larger snippets of code can be displayed across multiple lines using triple back ticks: 123. my-link {  text-decoration: underline;}If you want to get really fancy, you can even add syntax highlighting using Rouge.  Reference lists: The quick brown jumped over the lazy. Another way to insert links in markdown is using reference lists. You might want to use this style of linking to cite reference material in a Wikipedia-style. All of the links are listed at the end of the document, so you can maintain full separation between content and its source or reference. Full HTML: Perhaps the best part of Markdown is that you’re never limited to just Markdown. You can write HTML directly in the Markdown editor and it will just work as HTML usually does. No limits! Here’s a standard YouTube embed code as an example: "
    }, {
    "id": 12,
    "url": "http://localhost:4000/about-bundler/",
    "title": "About Bundler",
    "body": "2018/05/12 - gem install bundler installs the bundler gem through RubyGems. You only need to install it once - not every time you create a new Jekyll project. Here are some additional details: bundler is a gem that manages other Ruby gems. It makes sure your gems and gem versions are compatible, and that you have all necessary dependencies each gem requires. The Gemfile and Gemfile. lock files inform Bundler about the gem requirements in your site. If your site doesn’t have these Gemfiles, you can omit bundle exec and just run jekyll serve. When you run bundle exec jekyll serve, Bundler uses the gems and versions as specified in Gemfile. lock to ensure your Jekyll site builds with no compatibility or dependency conflicts. For more information about how to use Bundler in your Jekyll project, this tutorial should provide answers to the most common questions and explain how to get up and running quickly. "
    }, {
    "id": 13,
    "url": "http://localhost:4000/options-for-creating-new-site-with-jekyll/",
    "title": "Options for creating a new site with Jekyll",
    "body": "2018/01/12 - jekyll new &lt;PATH&gt; installs a new Jekyll site at the path specified (relative to current directory). In this case, Jekyll will be installed in a directory called myblog. Here are some additional details:  To install the Jekyll site into the directory you’re currently in, run jekyll new . If the existing directory isn’t empty, you can pass the –force option with jekyll new . –force.  jekyll new automatically initiates bundle install to install the dependencies required. (If you don’t want Bundler to install the gems, use jekyll new myblog --skip-bundle. ) By default, the Jekyll site installed by jekyll new uses a gem-based theme called Minima. With gem-based themes, some of the directories and files are stored in the theme-gem, hidden from your immediate view.  We recommend setting up Jekyll with a gem-based theme but if you want to start with a blank slate, use jekyll new myblog --blank To learn about other parameters you can include with jekyll new, type jekyll new --help. "
    }, {
    "id": 14,
    "url": "http://localhost:4000/quick-start-guide/",
    "title": "Let's test spoilers",
    "body": "2018/01/11 - Director Roland Suso Richter’s enigmatic psychological thriller (direct to video/DVD) was based upon screenwriter Michael Cooney’s own play “Point of Death” - a title that gave away the film’s entire plot twist premise. As in many similar films, such as Jacob’s Ladder (1990), Soul Survivors (2001), and The Butterfly Effect (2004), events and people were thoroughly distorted and confused because the protagonist was at the point of death. The tagline was misleading: “When You Don’t Have a Memory, How Can You Remember Who to Trust?” The mind-warping film opened with a hospital patient Simon Cable (Ryan Phillippe) awakening in a hospital with little knowledge (amnesia perhaps?) of what had happened, and why he was there, etc. He was told by attending Dr. Jeremy Newman (Stephen Rea) that it was July 29, 2002 (Simon thought it was the year 2000 - he was confused - he heard a doctor say 20:00 hours!) and that he had died for two minutes from cardiac arrest following the near-fatal accident – but he had been revived (“You’re as good as new”). Dr. Newman: “Simon, this is the 29th of July. The year is 2002. And your wife, whose name is Anna, is waiting outside. ” (The doctor left off four crucial additional words, revealed in the film’s ending. ) (Spoiler: Simon had died and was not resuscitated!). A major clue to everything that truly happened was the scene that played next under the credits - hospital staff failed to bring a patient back to life with a defibrillator after a car accident. Chest compressions failed and there was no pulse. A second major clue was provided by hospital orderly Travis (Stephen Graham): Everybody dies. No mystery there. But why and how everyone dies. Now, there’s a mystery worth solving. Probably the biggest mystery there is. So how do we do spoilers?: 1&lt;span class= spoiler &gt;My hidden paragraph here. &lt;/span&gt;"
    }, {
    "id": 15,
    "url": "http://localhost:4000/customer-service/",
    "title": "Inception Movie",
    "body": "2018/01/11 - Review products, books, movies, restaurant and anything you like on your Jekyll blog with Mediumish! JSON-LD ready for review property. How to use?: It’s actually really simple! Add the rating in your YAML front matter. It also supports halfs: 12345678910---layout: posttitle:  Inception Movie author: johncategories: [ Jekyll, tutorial ]tags: [red, yellow]image: assets/images/11. jpgdescription:  My review of Inception movie. Actors, directing and more.  rating: 4. 5---"
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});